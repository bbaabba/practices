{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f08d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "baseUrl = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query='\n",
    "plusUrl = input('검색어 입력: ')\n",
    "crawl_num = int(input('크롤링할 갯수 입력: '))\n",
    "\n",
    "url = baseUrl + quote_plus(plusUrl) # 한글 검색 자동 변환\n",
    "html = urlopen(url)\n",
    "res = html.read()\n",
    "soup = bs(res, 'html.parser')\n",
    "img = soup.find_all(class_='_img')\n",
    "\n",
    "n=1\n",
    "\n",
    "for i in img:\n",
    "    print(n)\n",
    "    imgUrl = soup.find(\"img\")[\"src\"]\n",
    "    urllib.request.urlretrieve(imgUrl, soup.find(\"img\")[\"alt\"]+'.jpg')\n",
    "    n += 1\n",
    "    if n > crawl_num:\n",
    "        break\n",
    "    \n",
    "    \n",
    "print('Image Crawling is done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d23cb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어 입력: 강아지\n",
      "크롤링할 갯수 입력(최대 50개): 30\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote_plus\n",
    " \n",
    "baseUrl = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query='\n",
    "plusUrl = input('검색어 입력: ') \n",
    "crawl_num = int(input('크롤링할 갯수 입력(최대 50개): '))\n",
    " \n",
    "url = baseUrl + quote_plus(plusUrl) # 한글 검색 자동 변환\n",
    "html = urlopen(url)\n",
    "soup = bs(html, \"html.parser\")\n",
    "img = soup.find_all(class_='_img')\n",
    " \n",
    "n = 1\n",
    "for i in img:\n",
    "    print(n)\n",
    "    imgUrl = i['data-source']\n",
    "    with urlopen(imgUrl) as f:\n",
    "        with open('./images/img' + str(n)+'.jpg','wb') as h: # w - write b - binary\n",
    "            img = f.read()\n",
    "            h.write(img)\n",
    "    n += 1\n",
    "    if n > crawl_num:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3e1643",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=106.0.5249.119)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 50번 페이지 다운\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mbody\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPAGE_DOWN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 2. 영상의 제목만 크롤링\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pp39\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:477\u001b[0m, in \u001b[0;36mWebElement.send_keys\u001b[1;34m(self, *value)\u001b[0m\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    475\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upload(local_file)\n\u001b[1;32m--> 477\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSEND_KEYS_TO_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m              \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys_to_typing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys_to_typing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pp39\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:633\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    631\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    632\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pp39\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:321\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    323\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\.conda\\envs\\pp39\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:242\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)\n\u001b[1;32m--> 242\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=106.0.5249.119)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver as wb\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# 1. 크롬 드라이버를 실행해서 유튜브 화면 실행\n",
    "driver = wb.Chrome()\n",
    "url=\"https://www.youtube.com/results?search_query=%EC%82%AC%EB%82%98%EA%B3%A0\"\n",
    "driver.get(url)\n",
    "\n",
    "# 컴퓨터가 페이지 다운하는 기능\n",
    "body = driver.find_element_by_tag_name(\"body\")\n",
    "# 50번 페이지 다운\n",
    "for i in range(1,50):\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "# 2. 영상의 제목만 크롤링\n",
    "soup = bs(driver.page_source, 'lxml')\n",
    "title = soup.select(\"a#video-title\")\n",
    "\n",
    "titleList=[]\n",
    "for i in range(len(title)):\n",
    "    titleList.append(title[i].text.strip())\n",
    "    \n",
    "for i in titleList:\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "# 3. 영상의 길이를 확인, 순수한 텍스트까지 출력\n",
    "lens = soup.select(\"div#overlays > ytd-thumbnail-overlay-time-status-renderer > span.style-scope\")\n",
    "\n",
    "lensList=[]\n",
    "for i in range(len(lens)):\n",
    "    lensList.append(lens[i].text.strip())\n",
    "\n",
    "for i in lensList:\n",
    "    print(i)\n",
    "# 4. 영상의 조회수\n",
    "soup.select(\"div#metadata  span\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36f5eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver as wb\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote_plus\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# driver = wb.Chrome()\n",
    "\n",
    "# baseUrl = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query='\n",
    "# plusUrl = input('검색어 입력: ')\n",
    "# crawl_num = int(input('크롤링할 갯수 입력: '))\n",
    "\n",
    "# url = baseUrl + quote_plus(plusUrl) # 한글 검색 자동 변환\n",
    "# html = urlopen(url)\n",
    "# res = html.read()\n",
    "# soup = bs(res, 'html.parser')\n",
    "\n",
    "# if not os.path.isdir(plusUrl+\"/\"):\n",
    "#     os.makedirs(plusUrl+\"/\")\n",
    "\n",
    "# driver.get(url)\n",
    "\n",
    "# # 50번 페이지 다운\n",
    "# body = driver.find_element_by_css_selector('body')\n",
    "# last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "# exitcounter = 0\n",
    "# while True :\n",
    "#     try : \n",
    "        \n",
    "#         body.send_keys(Keys.PAGE_DOWN)\n",
    "#         time.sleep(0.5)\n",
    "#         new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "#         if new_height == last_height:\n",
    "#             break\n",
    "#         last_height = new_height\n",
    "#     except :\n",
    "#         time.sleep(0.5)\n",
    "#         exitcounter += 1\n",
    "#         if exitcounter > 100 :\n",
    "#             break\n",
    "#         else :\n",
    "#             pass\n",
    "    \n",
    "        \n",
    "    \n",
    "# # soup = bs(driver.find_element_by_class_name, '_image _listImage')\n",
    "\n",
    "# images = driver.find_elements_by_class_name(\"_image _listImage\")\n",
    "# count = 1\n",
    "# for image in images:\n",
    "#     try:\n",
    "#         image.click()\n",
    "#         time.sleep(2)\n",
    "#         imgUrl = driver.find_element_by_xpath(\"/html/body/div[3]/div[2]/div/div[1]/section[2]/div/div[1]/div[1]/div[1]/div/div[1]/a/img\").get_attribute('src')\n",
    "#         urllib.request.urlretrieve(imgUrl, plusUrl + \"/\" + plusUrl + \"_\" + str(count) + \".jpg\")\n",
    "#         print(\"Image saved: {}.jpg\".format(count))\n",
    "#         count += 1\n",
    "#         if count == crawl_num :\n",
    "#             break\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "096b0528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어 입력: 새\n",
      "크롤링할 갯수 입력: 10\n",
      "Image saved: 0\n",
      "Image saved: 1\n",
      "Image saved: 2\n",
      "Image saved: 3\n",
      "Image saved: 4\n",
      "Image saved: 5\n",
      "Image saved: 6\n",
      "Image saved: 7\n",
      "Image saved: 8\n",
      "Image saved: 9\n"
     ]
    }
   ],
   "source": [
    "baseUrl = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query='\n",
    "plusUrl = input('검색어 입력: ')\n",
    "crawl_num = int(input('크롤링할 갯수 입력: '))\n",
    "\n",
    "url = baseUrl + quote_plus(plusUrl) # 한글 검색 자동 변환\n",
    "html = urlopen(url)\n",
    "res = html.read()\n",
    "soup = bs(res, 'html.parser')\n",
    "\n",
    "if not os.path.isdir(plusUrl+\"/\"):\n",
    "    os.makedirs(plusUrl+\"/\")\n",
    "driver = wb.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "body = driver.find_element_by_css_selector('body')\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "exitcounter = 0\n",
    "\n",
    "\n",
    "# 50번 페이지 다운\n",
    "driver.find_elements_by_class_name('wrap')\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "exitcounter = 0\n",
    "for i in range(int(crawl_num/3)) :\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(0.5)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "# soup = bs(driver.find_element_by_class_name, '_image _listImage')\n",
    "\n",
    "images = driver.find_elements_by_class_name(\"_image._listImage\")\n",
    "# print(images)\n",
    "count = 0\n",
    "for image in images:\n",
    "    image.click()\n",
    "    time.sleep(2)\n",
    "    imgUrl = driver.find_element_by_xpath(\"/html/body/div[3]/div[2]/div/div[1]/section[2]/div/div[2]/div/div/div[1]/div[1]/div/div/div[1]/div[1]/img\").get_attribute('src')\n",
    "    urllib.request.urlretrieve(imgUrl, plusUrl + \"/\" + plusUrl + \"_\" + str(count) + \".jpg\")\n",
    "    print(\"Image saved: {}\".format(count))\n",
    "    count += 1\n",
    "    if count == crawl_num :\n",
    "        break\n",
    "\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd5cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9902c6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
